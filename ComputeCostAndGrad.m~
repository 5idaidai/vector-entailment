function [ cost, grad, pred ] = ComputeCostAndGrad( theta, decoder, dataPoint, hyperParams )
%function [ cost, grad ] = ComputeCostAndGrad( theta, decoder, dataPoint, hyperParams )
%   Detailed explanation goes here

% Unpack theta.
[classifierMatrices, classifierMatrix, classifierBias, ...
    classifierParameters, wordFeatures, compositionMatrices,...
    compositionMatrix, compositionBias] ...
    = stack2param(theta, decoder);

% Unpack hyperparams.
NUM_RELATIONS = hyperParams.numRelations;
PENULT_DIM = hyperParams.penultDim;
DIM = hyperParams.dim;

leftTree = dataPoint.leftTree;
rightTree = dataPoint.rightTree;
trueRelation = dataPoint.relation;

% Make sure word features are current.
leftTree.updateFeatures(wordFeatures);
rightTree.updateFeatures(wordFeatures);

leftFeatures = leftTree.getFeatures();
rightFeatures = rightTree.getFeatures();

% Use the tensor layer to build classifier input:
tensorInnerOutput = ComputeInnerTensorLayer(leftFeatures, ...
    rightFeatures, classifierMatrices, classifierMatrix, classifierBias);
tensorOutput = Sigmoid(tensorInnerOutput);
tensorDeriv = SigmoidDeriv(tensorInnerOutput);

relationProbs = ComputeSoftmaxProbabilities(tensorOutput, classifierParameters);

% Increment local error
cost = Objective(trueRelation, relationProbs);

if nargout > 1
    % Initialize the gradients.
    localSoftmaxGradient = zeros(NUM_RELATIONS, PENULT_DIM + 1);
    localClassificationMatricesGradients = zeros(DIM , DIM * PENULT_DIM);
    localClassificationMatrixGradients = zeros(PENULT_DIM, 2 * DIM);
    localClassificationBiasGradients = zeros(PENULT_DIM, 1);
    localWordFeatureGradients = sparse([], [], [], ...
        size(wordFeatures, 1), size(wordFeatures, 2), 10);
    
    localCompositionMatricesGradients = zeros(DIM , DIM * PENULT_DIM);
    localCompositionMatrixGradients = zeros(PENULT_DIM, 2 * DIM);
    localCompositionBiasGradients = zeros(PENULT_DIM, 1);
    
    % Compute node softmax error, mid-left of p6 of tensor paper
    targetRelationProbs = zeros(length(relationProbs), 1);
    targetRelationProbs(trueRelation) = 1;
    softmaxDeltaFirstHalf = classifierParameters' * (relationProbs - targetRelationProbs);
    softmaxDeltaSecondHalf = SigmoidDeriv([1; tensorOutput]); % Intercept
    softmaxDelta = (softmaxDeltaFirstHalf .* softmaxDeltaSecondHalf);
    
    % TODO: Parallelize
    for relEval = 1:NUM_RELATIONS
        % Del from ufldl wiki on softmax
        localSoftmaxGradient(relEval, :) = ...
            -([1; tensorOutput] .* ...
            ((trueRelation == relEval) - relationProbs(relEval)))';
    end
    
    % Calculate third order tensor gradients for tensor layer
    for (relEval = 1:PENULT_DIM)
        Cols = (DIM*(relEval - 1))+1:(DIM*relEval);
        localClassificationMatricesGradients(:,Cols) = ...
            (tensorDeriv(relEval) * softmaxDelta(relEval + 1)) .* ...
            (leftFeatures * rightFeatures');
    end
    
    % Traverse tree - at each word feature vector node
      % - Compute Gradient for composition tensor layer, and add it in
      % - Compute downward delta
      % - Call both children, and compute their gradients
    
      
    % Calculate matrix gradients for tensor layer
    parfor (relEval = 1:PENULT_DIM)
        localClassificationMatrixGradients(relEval, :) = (tensorDeriv(relEval) * softmaxDelta(relEval + 1)) .* [leftFeatures; rightFeatures];
    end
    
    % Calculate vector gradients for tensor layer
    localClassificationBiasGradients = (tensorDeriv .* softmaxDelta(2:PENULT_DIM + 1));
    
    % Calculate gradients for word features
    
    % TODO: Fill in.
    localWordFeatureGradients = zeros(size(wordFeatures));
    
    %%%% USED TO COMPUTE WORD FEATURE GRADIENTS HERE %%%
    
    % First word
    softmaxDelta = localClassificationBiasGradients;
    innerTensorLayerMatrix = zeros(DIM, PENULT_DIM);
    for relNum = 1:PENULT_DIM
        Cols = (DIM*(relNum - 1))+1:(DIM*relNum);
        innerTensorLayerMatrix(:, relNum) = classifierMatrices(:,Cols) * rightFeatures;
    end
    thirdTerm = innerTensorLayerMatrix + classifierMatrix(:, 1:DIM)';
    classifierDeltaLeft = ...
        (thirdTerm * (softmaxDelta .* tensorDeriv))';
    
    [ upwardWordGradients, ...
      upwardCompositionMatricesGradients, ...
      upwardCompositionMatrixGradients, ...
      upwardCompositionBiasGradients ] = ...
       leftTree.getGradient(classifierDeltaLeft, wordFeatures, ...
                            compositionMatrices, compositionMatrix, ...
                            compositionBias);
    localWordFeatureGradients = localWordFeatureGradients ...
        + upwardWordGradients;
    localCompositionMatricesGradients = localCompositionMatricesGradients...
        + upwardCompositionMatricesGradients;
    localCompositionMatrixGradients = localCompositionMatrixGradients...
        + upwardCompositionMatrixGradients;
    localCompositionBiasGradients = localCompositionBiasGradients...
        + upwardCompositionBiasGradients;
               
               
    % Second word
    innerTensorLayerMatrix = zeros(DIM, PENULT_DIM);
    for relNum = 1:PENULT_DIM
        Cols = (DIM*(relNum - 1))+1:(DIM*relNum);
        innerTensorLayerMatrix(:, relNum) = leftFeatures' * classifierMatrices(:,Cols);
    end
    thirdTerm = innerTensorLayerMatrix + classifierMatrix(:, DIM+1:2*DIM)';    
    localWordFeatureGradients(rightTree.getWordIndex, :) = ...
        (thirdTerm * (softmaxDelta .* tensorDeriv))';
    
% Apply matrix
% innerTensorLayerOutput = innerTensorLayerOutput + classifierMatrix * [a; b];
% )
%     
%     S = zeros(DIM_COMBINED, 1);
%     for (relEval = 1:NUM_RELATIONS)
%         Cols = (DIM*(relEval - 1))+1:(DIM*relEval);
%         firstHalf = softmaxDelta(relEval) .* (sliceGradients(:,Cols) + sliceGradients(:,Cols)');
%         secondHalf = combinedFeatures;
%         S = S + (firstHalf * secondHalf');
%     end
%     messageDown = S .* SigmoidDeriv(combinedFeatures)';
%     
% In this setup, messageDown goes straight to the words.    
%     leftVocabIndex = leftTree.getWordIndex();
%     rightVocabIndex = rightTree.getWordIndex();
%     localWordFeatureGradients(leftVocabIndex, :) = messageDown(1:DIM);
%     localWordFeatureGradients(rightVocabIndex, :) = messageDown(DIM + 1:2 * DIM);
%     
    
    % Pack up gradients.
    grad = param2stack(localClassificationMatricesGradients, ...
        localClassificationMatrixGradients, ...
        localClassificationBiasGradients, localSoftmaxGradient, ...
        localWordFeatureGradients, localCompositionMatricesGradients, ...
        localCompositionMatrixGradients, localCompositionBiasGradients);
end

% Compute prediction if requested.
if nargout > 2
    [~, pred] = max(relationProbs);
end

end

