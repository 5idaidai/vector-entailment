\subsection*{Introduction}\label{sec:intro}
  % TODO: Trim and revise
  % Less focus on RNTNs, more on embedding spaces

Natural logic offers a powerful \emph{relational} conception of
semantics: the meanings for expressions are given, at least in part,
by their inferential connections with other expressions
\cite{vanBenthem08NATLOG,maccartney2009extended}. For instance,
\word{turtle} is analyzed, not primarily by its extension in the
world, but rather by its lexical network: it entails \word{reptile},
excludes \word{chair}, is entailed by \word{sea
  turtle}, and so forth. With generalized notions of entailment and
contradiction, these relationships can be defined for all lexical
categories as well as complex phrases, sentences, and even texts. The
resulting theories of meaning offer valuable new analytic tools for
tasks involving database inference, relation extraction, and textual
entailment.

These approaches are naturally paired with theories using distributed
(e.g., vector) representations, where meaning is also naturally
modeled as relational. Distributed representations have been used
successfully in a wide array of sophisticated language tasks,
including sentiment analysis, analogy completion, relation extraction,
and named entity recognition. However, it remains an open question
whether it is possible to train such representations to support the
rich, diverse logical reasoning captured by natural logic; while such
representations excel at synonymy (similarity), the results are more
mixed for entailment, contradiction, and mutual consistency.

Using the natural logic of \cite{maccartney2009extended} as our formal
model, we address this open question for two classes of neural model:
plain neural networks and neural tensor networks (NTNs;
\cite{socher2013acl1}). The natural logic is built from the seven
relations defined in Table~\ref{b-table}. Its formal properties and
inferential strength of the natural logic are now well-understood
\cite{Icard:Moss:2013,Icard:Moss:2013:LILT}, so it provides a rigorous
and challenging set of goals for our distributed representations. To
keep the discussion managable, we limit attention to experiments
involving the lexicon; for a more extended treatment involving complex
expressions involving logical connectives and quantifiers, see
\cite{Bowman:Potts:Manning:2014}.

In our first experiment, we use the pre-specified logical grammar to
generate controlled data sets and assses the ability of the two
classes of neural network to learn the core underlying relational
algebra from this simulated data. In our second experiment, we define
a simple modification of the logical grammar so that it aligns well
with the WordNet noun graph, and we again assess our two classes of
RNN on this data. The controlled data of our first experiment helps us
to achieve analytic insights into what the models are able to learn,
and the large, diverse lexicon of the second experiment shows us how
they fare in the real world. We find that the plain RNN achieves only
mixed results in these experiments, whereas the stronger RNTN model
generalizes well in both cases, suggesting that it has in fact
learned, or at least learned to simulate, our target logical concepts.
% These experiments differentiate the increased power of RNTNs better
% than previous work and provide the most convincing demonstration to
% date of the ability of neural networks to model semantic inferences
% in complex natural language sentences.

\begin{table}[tp]
  \centering
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle, reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile, turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch, sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle, warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able, unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle, pet}\\
    \bottomrule
  \end{tabular}
  \caption{The seven natural logic relations of \cite{maccartney2009extended}. 
    $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, 
    and the relation $\natind$ applies whenever none of the other six do.} %, including when there 
    %is insufficient knowledge to choose a label.}
  \label{b-table}
\end{table}

% TODO: Add citations on related work in structuring relations in embedding spaces:
% - Representing partâ€“whole relations in conceptual spaces
% - Something McCallum/Universal Schema?
