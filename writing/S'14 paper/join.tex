\section{Relation composition}

In order for a model to be able to learn to mimic the behavior of a relational logic like the one presented here from a finite amount data, it must be able to learn to deduce new relations from seen relations. The simplest such deductions involve facts about the relations themselves that do not involve considering the internal structure of the things being compared. For example, given that $a\sqsupset b$ and $b\sqsupset c$ one can conclude that $a\sqsupset c$ by the transitivity of $\sqsupset$, even without understanding $a$, $b$, or $c$. These seven relations support more than just transitivity: MacCartney and Manning's \cite{maccartney2009extended} join table defines 32 valid inferences that can be made on the basis of pairs of relations of the form $a R b$ and $b R' c$, including several less intuitive ones such as that if $a \natneg b$ and $b~|~c$ then $a \sqsupset c$. 

\begin{figure}[t]
\begin{center}
\begin{tabular}{ll|lll}
$a := \{1, 3, 4, 5, 6\}	$&~~~&~~~& $a \equiv a$	    	& $a~\#~c$	\\
$b := \{0, 3, 5, 6\}	$&~~~&~~~& $e \sqsupset c$	&$b \smallsmile c$		\\
$c := \{1, 2, 3, 4\}	$&~~~&~~~& $d \smallsmile e$	& $b~\#~d$		\\
$d := \{0, 4\}		$&~~~&~~~& $a \sqsubset e$	& $ d \equiv d$	\\
$e := \{1, 2, 3, 4, 5, 6\}$&~~~&~~~& $a~\#~b$		& ... 	\\
\end{tabular}
\end{center}

\caption{Some sample randomly generated sets, and some of the relations defined between them.  \label{lattice-figure}} 
\end{figure}

We test the model's ability to learn this behavior by creating an artificial dataset of terms which represent sets of numbers. Since MacCartney and Manning's set of relations hold between sets as well as between sentences, we can use the underlying set structure to generate the all of the relations that hold between any pair of these terms, as in Figure \ref{lattice-figure}. We train the model defined above on a subset of these relations, but rather then presenting the model with a pair of tree-structured sentences as inputs, simply present it with two single terms, each of which corresponds to a single vector in the (randomly initialized) vocabulary matrix $V$, ensuring that the model has no information about the terms being compared except the relations between them.

We generate 80 randomly generated sets drawing from the same seven elements, and create a dataset consisting of the relations between every pair of sets, yielding 6400 pairs. 3200 of these pairs were then chosen as a test dataset, and that test dataset was further split into the 2960 examples that can be provably derived from the test data using MacCartney and Manning's join table (or by the symmetry of the relations in about half of the cases) and the 240 that cannot. % TODO: Say more about symmetry?

We tested a version of both the RNN model and the RNTN model on these data. In both cases, the models were implemented exactly as described in Section \ref{methods}, but since the items being compared are single terms rather than full tree structures, the composition layer was not used, and the two models differed only in which layer function was used for the comparison layer.
We found that the RNTN model worked best with 11 dimensional vector representations for the 80 sets and a 90 dimensional feature vector for the classifier. This model was able to correctly label 99.3\% of the derivable test examples, and 99.1\% of the remaining examples. The simpler RNN model worked best with 11 and 75 dimensions, respectively, but was able to achieve accuracies of only 90.0\% and 87.\%, respectively.

% TODO: T-sne the RNTN model's embeddings.

These results are fairly simple to interpret. The RNTN model was able to accurately encode the relations between the terms in the geometric relations between their vectors, and was able to then use that information to recover relations that were not overtly included in the training data. The RNN model was able to approximate this behavior only incompletely. It is possible but not likely that it could be made to find a good solution with further optimization on different learning algorithms, or that it would do better on a larger universe of sets for which there would be a larger set of training data to learn from.

