\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage[leqno, fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{qtree}
\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xcolor}



\definecolor{mylinkcolor}{rgb}{0,0,0} % black
\hypersetup{colorlinks, linkcolor=mylinkcolor, urlcolor=mylinkcolor, citecolor=mylinkcolor}

\newcommand{\nateq}{\equiv}
\newcommand{\natind}{\mathbin{\#}}
%\newcommand{\natneg}{\raisebox{2px}{\tiny\thinspace$\wedge$\thinspace}}
\newcommand{\natneg}{\mathbin{^{\wedge}}}
\newcommand{\natfor}{\sqsubset}
\newcommand{\natrev}{\sqsupset}
\newcommand{\natalt}{\mathbin{|}}
\newcommand{\natcov}{\mathbin{\smallsmile}}

\newcommand{\plneg}{\mathop{\textit{not}}}
\newcommand{\pland}{\mathbin{\textit{and}}}
\newcommand{\plor}{\mathbin{\textit{or}}}



% Strikeout
\newlength{\howlong}\newcommand{\strikeout}[1]{\settowidth{\howlong}{#1}#1\unitlength0.5ex%
\begin{picture}(0,0)\put(0,1){\line(-1,0){\howlong\divide\unitlength}}\end{picture}}

\newcommand{\True}{\texttt{T}}
\newcommand{\False}{\texttt{F}}
\usepackage{stmaryrd}
\newcommand{\sem}[1]{\ensuremath{\llbracket#1\rrbracket}}


\renewcommand{\bibsection}{\subsubsection*{References}}

\usepackage{gb4e}

\def\ii#1{\textit{#1}}

\newcommand{\mynote}[1]{{\color{red}\framebox{\begin{tabular}{p{0.9\textwidth}}\footnotesize#1 \end{tabular}}}}


\title{Recursive Neural Networks for Learning Logical Semantics}

\author{
Samuel R.\ Bowman$^{\ast\dag}$ \\
\texttt{sbowman@stanford.edu} \\[2ex]
$^{\ast}$Stanford Linguistics \\
\And
Christopher Potts$^{\ast}$\\
\texttt{cgpotts@stanford.edu} \\[2ex]
$^{\dag}$Stanford NLP Group
\And
Christopher D.\ Manning$^{\ast\dag\ddag}$\\
\texttt{manning@stanford.edu}\\[2ex]
$^{\ddag}$Stanford Computer Science
}

% \author{
% Samuel R.\ Bowman \\
% NLP Group, Dept.\ of Linguistics\\
% Stanford University\\
% Stanford, CA 94305-2150 \\
% \texttt{sbowman@stanford.edu}
%  \And
%  Christopher Potts \\
% Dept.\ of Linguistics\\
% Stanford University\\
% Stanford, CA 94305-2150 \\
% \texttt{cgpotts@stanford.edu}
%  \And
% Christopher D.\ Manning \\
% NLP Group,  Depts.\ of Computer Science and Linguistics\\
% Stanford University\\
% Stanford, CA 94305-2150 \\
% \texttt{manning@stanford.edu}
% }

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}
\maketitle

% Compare with Grefenstette etc?

  Supervised recursive neural network models (RNNs) for sentence
  meaning have been successful in an array of sophisticated language
  tasks, but it remains an open question whether they can learn
  compositional semantic grammars that support logical deduction.  We
  address this question directly by for the first time evaluating
  whether each of two classes of neural model --- plain RNNs and
  recursive neural tensor networks (RNTNs) --- can correctly learn
  relationships such as entailment and contradiction between pairs of
  sentences, where we have generated controlled data sets of sentences
  from a logical grammar.  Our first experiment evaluates whether
  these models can learn the basic algebra of logical relations
  involved. Our second and third experiments extend this evaluation to
  complex recursive structures and sentences involving quantification.
  We find that the plain RNN achieves only mixed results on all three
  experiments, whereas the stronger RNTN model generalizes well in
  every setting and appears capable of learning suitable
  representations for natural language logical inference.

\subsection*{Recursive neural network models}

\begin{figure}[hp]
  \centering
  \input{figure1}
  % \caption{The model structure used to compare \ii{((all reptiles) walk)} and \ii{((some turtles) move)}. 
  %  The same structure is used for both the RNN and RNTN layer functions.} 
  \label{sample-figure}
\end{figure}

In our experiments, we train pairs of recursive (tree structured) neural network models \cite{socher2013acl1} which are joined together with a shared top layer that generates features for a classifier. The classifier predicts the logical relation that holds between the sentences represented by the two trees. For an activation function, we use either a plain NN layer or a tensor combination layer.

% TODO gold parse structures

\subsection*{Reasoning about semantic relations}

\begin{table}[h]
  \centering
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle, reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile, turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch, sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle, warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able, unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle, pet}\\
    \bottomrule
  \end{tabular}
  \label{b-table}
\end{table}
 
Our models classify into the seven relations from \cite{maccartney2009extended}, shown in the table below, which define possible relationships between pairs of terms or sentences of natural language in terms of their set-theoretic denotations.
If any model is to learn the behavior of a relational logic like the one
presented here from a finite amount of data, it must learn to deduce new
relations from already seen relations. Our first experiment evaluates the ability of our models to do this over pairs of atomic symbols in a large corpus of artificial data. The model is trained on examples like \{$a \natfor b$, $b \natneg c$\}, and tested on examples that follow from them, like \{$a \natalt c$\}.

\subsection*{Recursive structure in propositional logic}\label{sec:recursion}

Our second experiment introduces compositionality to our examples, training on short statements of propositional logic, like $\plneg a\natrev(a \pland b)$. We train our models on only pairs of statements with up to four symbols, but observe that the RNN performs reasonably both on those and on much longer test pairs. 

\begin{figure}[h]
  \centering
  \includegraphics[width=4in]{recursion\string_results\string_final.eps}
  \label{prop-results}
\end{figure}

\subsection*{Reasoning with natural language quantifiers and negation}\label{sec:quantifiers}

For our third experiment, we generate pairs of sentences in which each sentence contains one quantifier, and any of a small set of common nouns, as in the example \textit{(no warthogs) move $\natfor$ (no (not reptiles)) swim}. The parentheses indicate the tree structure for each sentence as it will be used by the model. We defined several different types of train--test split for this experiment. A tuned RNTN model performed either well ($>85\%$ accuracy) or perfectly on all of them, while a tuned RNN did not break 80\% in any setting.


\bibliographystyle{unsrtnat}

\small % Note: Explicitly allowed in style guide
\bibliography{MLSemantics} 

\end{document}